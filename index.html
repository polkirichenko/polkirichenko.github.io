<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="shortcut icon" href="favicon2.ico" />

    <link href="https://fonts.googleapis.com/css?family=Montserrat:300" rel="stylesheet"> 
    <link rel="stylesheet" href="stylesheets/styles.css">
  </head>

  <body>
      <style>
      body {
        background-color: #FFFFFF
      }</style>
    <div class="wrapper">
      <header>        
        <!---->
        <center><img src="polina.jpg" alt="Polina" /></center>
        <!---->
        <h1 style="text-align:center;"><a href="https://polkirichenko.github.io/"><font color="black">Polina Kirichenko</font></a></h1>

       <!-- <ul class="downloads">
            <li><a href="https://github.com/PolinaKirichenko"><strong>Github</strong></a></li>
            <li><a href="https://scholar.google.ru/citations?user=05uQHIgAAAAJ&hl=en"><strong>Google Scholar</strong></a></li>
          </ul> -->


        <p style="text-align:center;">contact me at pk1822@nyu.edu<br>or on <a href="https://twitter.com/polkirichenko">twitter</a></p>
        <p style="text-align:center;"> [<a href="https://scholar.google.com/citations?user=05uQHIgAAAAJ&hl=en&oi=ao">Google Scholar</a>, <a href="https://www.semanticscholar.org/author/P.-Kirichenko/67146006">Semantic Scholar</a>, <a href="CV.pdf">CV</a>] </p>
        

      </header>
      <section align="justify">


<p>I am a machine learning researcher interested in generalization, robustness, and fairness, among other topics.
  I recently completed my PhD at <a href="https://cds.nyu.edu/"> New York University Center for Data Science</a> working with
  professor <a href="https://cims.nyu.edu/~andrewgw/">Andrew Gordon Wilson</a>. I was also a
  Visiting Researcher at <a href="https://ai.meta.com/research/">FAIR Labs</a> (Meta AI) working with
  <a href="https://markibrahim.me/">Mark Ibrahim</a> and
  <a href="https://dianebouchacourt.github.io/">Diane Bouchacourt</a>.
  During my PhD, I interned at <a href="https://ai.meta.com/research/">Meta AI</a>, <a href="https://deepmind.google/">Google DeepMind</a> and <a href="https://www.cshl.edu/">Cold Spring Harbor Laboratory</a>.
  I received a BS in Computer Science at <a href="https://www.hse.ru/en/">Higher School of Economics</a>
    where I worked with professor <a href="https://bayesgroup.ru/people/dmitry-vetrov/">Dmitry&nbsp;Vetrov</a>.
  I was also a visiting research student at <a href="https://www.epfl.ch/en/">EPFL</a> with professors
    <a href="https://people.epfl.ch/martin.jaggi">Martin Jaggi</a> and <a href="https://people.csail.mit.edu/alistarh/">Dan Alistarh</a>.
  I am a recipient of the <a href="https://buildyourfuture.withgoogle.com/scholarships/generation-google-scholarship-emea">Google Generation Scholarship</a> and the DeepMind fellowship.
  </p>

<!-- <p>I am working on <strong>deep learning robustness to distribution shift and out-of-distribution generalization</strong>. -->
  <!-- I am also broadly interested in machine learning <strong>reliability, uncertainty estimation and generative models</strong>.</p> -->

<p> My research focuses on building <strong>trustworthy and reliable machine learning models</strong>. In particular, I am interested in:
<ul>
    <li style="margin-bottom: 5px;">Robustness to distribution shifts and out-of-distribution generalization;</li>
    <li style="margin-bottom: 5px;">Fairness and addressing biases in models and data;</li>
    <li style="margin-bottom: 5px;">Out-of-distribution detection, uncertainty estimation and calibration;</li>
    <li style="margin-bottom: 5px;">Understanding generalization and representations learning mechanisms in neural networks.</li>
</ul>
  </p>


<p>If you are an undergraduate or masters student interested in collaborating on research projects or looking for advice on PhD applications, please reach out!</p>



</section>

<section>
  <h2>
    Publications
</h2>
<ul id="publications" >

    <li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Modeling Caption Diversity in Contrastive Vision-Language Pretraining</strong>
        </span>
        <br />
        <span class='authors'>
          Samuel Lavoie, <strong>Polina Kirichenko*</strong>, Mark Ibrahim*, Mahmoud Assran, Andrew Gordon Wildon, Aaron Courville, Nicolas Ballas
        </span>
        <br />
        <span class='conference'>
            <i><strong><i>International Conference on Machine Learning (ICML),&nbsp;2024</i></strong></i><!--
     --></span>
        <br />
        [<a href="https://arxiv.org/abs/2405.00740">arXiv</a>]
    </li>

    <li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Does Progress On Object Recognition Benchmarks Improve Generalization on Crowdsourced Global Data?</strong>
        </span>
        <br />
        <span class='authors'>
          Megan Richards, <strong>Polina Kirichenko</strong>, Diane Bouchacourt, Mark Ibrahim
        </span>
        <br />
        <span class='conference'>
            <i>ICML Data-centric Machine Learning Research Workshop,&nbsp;2023; </i><!--
     --></span>
        <br />
        <span class='conference'>
            <i><strong><i>International Conference on Learning Representations (ICLR),&nbsp;2024</i></strong></i><!--
     --></span>
        <br />
        [<a href="https://arxiv.org/abs/2307.13136">arXiv</a>]
    </li>


    <li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Understanding the Detrimental Class-level Effects of Data Augmentation</strong>
        </span>
        <br />
        <span class='authors'>
          <strong>Polina Kirichenko</strong>, Mark Ibrahim, Randall Balestriero, Diane Bouchacourt, Rama&nbsp;Vedantam, Hamed Firooz, Andrew&nbsp;Gordon&nbsp;Wilson
        </span>
        <br />
        <span class='conference'>
            <i>ICML workshop on Spurious Correlations, Invariance, and Stability,&nbsp;2023; </i><!--
     --></span>
        <br />
        <span class='conference'>
            <i><strong><i>Neural Information Processing Systems (NeurIPS),&nbsp;2023</i></strong></i><!--
     --></span>
        <br />
        [<a href="https://arxiv.org/abs/2401.01764">arXiv</a>]
    </li>


    <li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations</strong>
        </span>
        <br />
        <span class='authors'>
          <strong>Polina Kirichenko*</strong>, Pavel Izmailov*, Andrew&nbsp;Gordon&nbsp;Wilson
        </span>
        <br />
        <span class='conference'>
            <i>ICML workshop on Spurious Correlations, Invariance, and Stability,&nbsp;2022; <i><strong><i>oral presentation</i></strong></i></i><!--
     --></span>
        <br />
        <span class='conference'>
            <i><strong><i>International Conference on Learning Representations (ICLR),&nbsp;2023; spotlight (notable-top-25%)</i></strong></i><!--
     --></span>
        <br />
        [<a href="https://arxiv.org/abs/2204.02937">arXiv</a>, <a href="https://github.com/PolinaKirichenko/deep_feature_reweighting">code</a>]
    </li>

	<li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>On Feature Learning in the Presence of Spurious Correlations</strong>
        </span>
        <br />
        <span class='authors'>
          Pavel Izmailov*, <strong>Polina Kirichenko*</strong>, Nate, Gruver*, Andrew&nbsp;Gordon&nbsp;Wilson
        </span>
        <br />
        <span class='conference'>
            <strong><i>Neural Information Processing Systems (NeurIPS),&nbsp;2022</i></strong><!--
     --></span>
     <br />
        [<a href="https://arxiv.org/abs/2210.11369">arXiv</a>, <a href="https://github.com/izmailovpavel/spurious_feature_learning">code</a>]
    </li>

    <li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Chroma-VAE: Mitigating Shortcut Learning with Generative Classifiers</strong>
        </span>
        <br />
        <span class='authors'>
          Wanqian Yang, <strong>Polina Kirichenko</strong>, Micah Goldblum, Andrew&nbsp;Gordon&nbsp;Wilson
        </span>
        <br />
        <span class='conference'>
            <strong><i>Neural Information Processing Systems (NeurIPS),&nbsp;2022</i></strong><!--
     --></span>
     <br />
     [<a href="https://arxiv.org/abs/2211.15231">arXiv</a>]
    </li>

	<li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Does Knowledge Distillation Really Work?</strong>
        </span>
        <br />
        <span class='authors'>
          Samuel Stanton, Pavel Izmailov, <strong>Polina Kirichenko</strong>, Alexander&nbsp;A.&nbsp;Alemi, Andrew&nbsp;Gordon&nbsp;Wilson
        </span>
        <br />
        <span class='conference'>
            <strong><i>Neural Information Processing Systems (NeurIPS),&nbsp;2021</i></strong><!--
     --></span>
        <br />
        [<a href="https://arxiv.org/abs/2106.05945">arXiv</a>]
    </li>
    

	<li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Task-agnostic Continual Learning with Hybrid Probabilistic Models</strong>
        </span>
        <br />
        <span class='authors'>
          <strong>Polina Kirichenko</strong>, Mehrdad Farajtabar, Dushyant Rao, Balaji Lakshminarayanan, Nir&nbsp;Levine, Ang&nbsp;Li, Huiyi&nbsp;Hu, Andrew&nbsp;Gordon&nbsp;Wilson, Razvan Pascanu
        </span>
        <br />
        <span class='conference'>
            <i>ICML Workshop on Invertible Neural Networks, Normalizing Flows, and Explicit Likelihood Models (spotlight talk),&nbsp;2021</i><!--
     --></span>
        <br />
        [<a href="https://arxiv.org/abs/2106.12772">arXiv</a>,
         <a href="hcl-poster-icml.pdf">poster</a>]
    </li>


    <li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Why Normalizing Flows Fail to Detect Out-of-Distribution Data</strong>
        </span>
        <br />
        <span class='authors'>
          <strong>Polina Kirichenko*</strong>, Pavel Izmailov*, Andrew Gordon Wilson
        </span>
        <br />
        <span class='conference'>
            <i>ICML workshop on Invertible Neural Networks and Normalizing Flows,&nbsp;2020</i><!--
     --></span>
        <br />
        <span class='conference'>
            <strong><i>Neural Information Processing Systems (NeurIPS),&nbsp;2020</i></strong><!--
     --></span>
        <br />
        [<a href="https://arxiv.org/abs/2006.08545">arXiv</a>,
         <a href="nf_neurips_poster.pdf">poster</a>]
    </li>
    <li>
        <span class='title'>
            <strong>Semi-Supervised Learning with Normalizing Flows</strong>
        </span>
        <br />
        <span class='authors'>
          Pavel Izmailov*, <strong>Polina Kirichenko*</strong>, Marc Finzi*, Andrew Gordon Wilson
        </span>
        <br />
        <span class='conference'>
            <i>ICML workshop on Invertible Neural Nets and Normalizing Flows,&nbsp;2019</i><!--
     --></span>
        <br />
        <span class='conference'>
            <i>14th Women in Machine Learning workshop (co-located with NeurIPS),&nbsp;2019</i><!--
     --></span>
        <br />
        <span class='conference'>
            <strong><i>International Conference on Machine Learning (ICML),&nbsp;2020</i></strong><!--
     --></span>
        <br />
        [<a href="https://arxiv.org/abs/1912.13025">arXiv</a>,
         <a href="http://proceedings.mlr.press/v119/izmailov20a.html">PMLR</a>,
         <a href="https://github.com/izmailovpavel/flowgmm">code</a>,
         <a href="sslnf_poster.pdf">poster</a>]
    </li>
    <li>
        <span class='title'>
            <strong>Subspace Inference for Bayesian Deep Learning</strong>
        </span>
        <br />
        <span class='authors'>
			Pavel Izmailov*, Wesley Maddox*, <strong> Polina Kirichenko*</strong>, Timur Garipov*, Dmitry Vetrov, Andrew&nbsp;Gordon&nbsp;Wilson
        </span>
        <br />
         <span class='conference'>
            <i>ICML workshop on Uncertainty & Robustness in Deep Learning (contributed talk),&nbsp;2019</i><!--
     --></span>
        <br />
        <span class='conference'>
            <strong><i>Uncertainty in Artificial Intelligence (UAI),&nbsp;2019</i></strong><!--
     --></span>
        <br />
        [<a href="https://arxiv.org/abs/1907.07504">arXiv</a>,
         <a href="https://github.com/wjmaddox/drbayes">code</a>,
         <a href="udl-poster.pdf">UDL poster</a>,
         <a href="uai-poster.pdf">UAI poster</a>]
    </li>
    <li>
        <span class='title'>
            <strong>SWALP: Stochastic Weight Averaging in Low-Precision Training</strong>
        </span>
        <br />
        <span class='authors'>
			Guandao Yang, Tianyi Zhang, <strong>Polina Kirichenko</strong>, Junwen Bai, Andrew Gordon Wilson, Christopher&nbsp;De&nbsp;Sa
        </span>
        <br />
        <span class='conference'>
             <strong><i>International Conference on Machine Learning (ICML),&nbsp;2019</i></strong><!--
     --></span>
        <br />
        [<a href="https://arxiv.org/abs/1904.11943">arXiv</a>,
         <a href="http://proceedings.mlr.press/v97/yang19d.html">PMLR</a>,
         <a href="https://github.com/stevenygd/SWALP">code</a>]
    </li>


  </section>




<section>
  <h2>
    Invited Talks
</h2>
<ul id="talks" >

    <li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Towards Robust and Reliable Deep Learning</strong>
        </span>
        <br />
        <span class='place'>
        Princeton,  Visual AI Lab seminar
        </span>
        <br />
    </li>

	<li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations</strong>
        </span>
        <br />
        <span class='place'>
        Oral presentation at ICML 2022 Workshop on Spurious Correlations, Invariance, and Stability
        </span>
        <br />
        [<a href="https://icml.cc/virtual/2022/workshop/13461">video</a>]
    </li>

	<li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Applications of Normalizing Flows: Semi-Supervised Learning, Anomaly Detection, and Continual Learning</strong>
        </span>
        <br />
        <span class='place'>
        <strong>Keynote talk</strong> at ICML 2021 Workshop on Representation Learning for Finance and E-Commerce Applications
        </span>
        <br />
        [<a href="https://icml.cc/Conferences/2021/ScheduleMultitrack?event=8361">video</a>]
    </li>

    <li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Task-agnostic Continual Learning with Hybrid Probabilistic Models</strong>
        </span>
        <br />
        <span class='place'>
        Spotlight talk at INNF+ workshop at ICML 2021
        </span>
        <br />
        [<a href="https://icml.cc/virtual/2021/workshop/8360">video</a>]
    </li>

	<li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Understanding Semantic Anomaly Detection with Generative Networks</strong>
        </span>
        <br />
        <span class='place'>
        ML Collective 2021, Deep Learning: Classics and Trends
        </span>
        <br />
        [<a href="https://rosanneliu.com/dlctfs/dlct_210226.pdf">slides</a>]
    </li>

	<li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Normalizing Flows for Anomaly Detection</strong>
        </span>
        <br />
        <span class='place'>
      Technical University of Denmark
        </span>
        <br />
        [<a href="https://youtu.be/Bts0jLU41a8?t=1486">video</a>]
    </li>

	<li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Anomaly Detection via Generative Models</strong>
        </span>
        <br />
        <span class='place'>
      Open Data Science DafaFest 2020, Uncertainty in ML Workshop
        </span>
        <br />
        [<a href="https://ods.ai/tracks/uncertainty-estimation-in-ml-df2020/4b59299d-0f36-4cfb-b72d-c3a2c9140f48">video</a>]
    </li>

	<li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Why Normalizing Flows Fail to Detect Out-of-Distribution Data</strong>
        </span>
        <br />
        <span class='place'>
      INNF+ workshop at ICML 2020; NeurIPS 2020
        </span>
        <br />
        [<a href="https://slideslive.com/38931453/why-normalizing-flows-fail-to-detect-outofdistribution-data">ICML video</a>,
         <a href="https://nips.cc/virtual/2020/protected/poster_ecb9fe2fbb99c31f567e9823e884dbec.html">NeurIPS video</a>]
    </li>
  
    <li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>How do we build neural networks we can trust?</strong>
        </span>
        <br />
        <span class='place'>
      Broad Institute of MIT and Harvard 
        </span>
        <br />
        [<a href="https://www.youtube.com/watch?v=GXs9Pmp6IKQ&feature=youtu.be&list=PLlMMtlgw6qNjROoMNTBQjAcdx53kV50cS">video</a>,
        <a href="MIA_talk.pdf">slides</a>]
    </li>

    <li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Subspace Inference for Bayesian Deep Learning</strong>
        </span>
        <br />
        <span class='place'>
        ICML workshop on Uncertainty & Robustness in Deep Learning
        </span>
        <br />
        [<a href="https://www.facebook.com/icml.imls/videos/320132412242165/?__xts__[0]=68.ARAVE0qFWSNt-GsHzKLAlU1lZSCw4FENJXcyjPNmenkT3SSPm4B2Ib1MPabxMBWmdBT2zgCjJHensO1ZQdKuezoWD7ycEdtgPu0YwfjA3d0F6tqqeJL2-xzR-VWLWMxu97LclHmIA9pSCOG_43utM8o-_q8Tc6LYrnm57RHX3uBGezj53Ee8Qbgne6kBiDJxuQIPpKEuszxmkvgSr3qN1QvIcm9QpIU7jiNbwat2Se6rIm7aj0dV2RxtrgrahnyDDHcUqq0HRfHlkLGfX8jsO_IeKoEqDFelMVJrQLNg0196rM8xJTbB1jrMPV2GlZJr-ebE4h_SPuUa62LVfoxJFBszgk-RUvmvDgI&__tn__=-R">video</a>,
        <a href="subspaces_slides.pdf">slides</a>]
    </li>



  </section>



    </div>
    <script src="/assets/js/scale.fix.js"></script>
  </body>
</html>

