<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="shortcut icon" href="favicon2.ico" />

    <link href="https://fonts.googleapis.com/css?family=Montserrat:300" rel="stylesheet"> 
    <link rel="stylesheet" href="stylesheets/styles.css">
  </head>

  <body>
      <style>
      body {
        background-color: #FFFFFF
      }</style>
    <div class="wrapper">
      <header>        
        <!---->
        <center><img src="polina.jpg" alt="Polina" /></center>
        <!---->
        <h1 style="text-align:center;"><a href="https://polkirichenko.github.io/"><font color="black">Polina Kirichenko</font></a></h1>

       <!-- <ul class="downloads">
            <li><a href="https://github.com/PolinaKirichenko"><strong>Github</strong></a></li>
            <li><a href="https://scholar.google.ru/citations?user=05uQHIgAAAAJ&hl=en"><strong>Google Scholar</strong></a></li>
          </ul> -->


        <p style="text-align:center;">contact me at pk1822@nyu.edu<br>or on <a href="https://twitter.com/polkirichenko">twitter</a></p>
        <p style="text-align:center;"> [<a href="https://scholar.google.com/citations?user=05uQHIgAAAAJ&hl=en&oi=ao">Google Scholar</a>, <a href="https://www.semanticscholar.org/author/P.-Kirichenko/67146006">Semantic Scholar</a>, <a href="CV.pdf">CV</a>] </p>
        

      </header>
      <section align="justify">


<p>I am a PhD candidate at New York University Center for Data Science working with
  professor <a href="https://cims.nyu.edu/~andrewgw/">Andrew Gordon Wilson</a>. I am also a
  Visiting Researcher at FAIR Labs, Meta AI working with
  <a href="https://scholar.google.com/citations?hl=en&user=AqYyoCMAAAAJ&view_op=list_works&sortby=pubdate">Mark Ibrahim</a> and
  <a href="https://scholar.google.com/citations?hl=en&user=iXOzeWUAAAAJ&view_op=list_works&sortby=pubdate">Diane Bouchacourt</a>.
  I am working on <strong>deep learning robustness to distribution shift and out-of-distribution generalization</strong>.
  I am also broadly interested in machine learning <strong>reliability, uncertainty estimation and generative models</strong>.
  During my PhD studies at NYU I spent time at Meta AI, Google DeepMind and Cold Spring Harbor Laboratory.
  My PhD research was supported by DeepMind fellowship in 2019-2020.
  </p>

  <p>Before joining NYU, I was a PhD student in Operations Research and Information Engineering at Cornell University.
    I received a BS in Computer Science at <a href="https://www.hse.ru/en/">Higher School of Economics</a>.
    During my undergrad, I worked at <a href="https://bayesgroup.ru/">Bayesian Methods research group</a> with
    <a href="https://bayesgroup.ru/people/dmitry-vetrov/">Dmitry&nbsp;Vetrov</a>
    and interned at Machine Learning and Optimization Lab at EPFL working with
    <a href="https://people.epfl.ch/martin.jaggi">Martin Jaggi</a> and <a href="https://people.csail.mit.edu/alistarh/">Dan Alistarh</a>.</p>

<!--   <p> In summer 2022, I interned at Meta AI with <a href="https://scholar.google.com/citations?user=4pKOL5gAAAAJ&hl=en&oi=ao">Hamed Firooz</a>,
    <a href="https://randallbalestriero.github.io/">Randall Balestriero</a> and <a href="https://vrama91.github.io/">Ramakrishna Vedantam</a>
    and worked on biases of data augmentations.
	In summer 2021, I interned at <a href="https://www.cshl.edu/">Cold Spring Harbor Laboratory</a> with
    <a href="http://zadorlab.labsites.cshl.edu/">Tony Zador</a> and worked on meta-learning and neuroscience applications. 
     In summer 2020, I interned at DeepMind with
    <a href="https://farajtabar.github.io/">Mehrdad Farajtabar</a>,
    <a href="https://sites.google.com/view/razp">Razvan Pascanu</a>
    and <a href="http://www.gatsby.ucl.ac.uk/~balaji/">Balaji Lakshminarayanan</a>, and worked on
    task-agnostic continual learning.
  In summer 2018, I interned at Machine Learning and Optimization Lab at EPFL and worked with
  professors <a href="https://people.epfl.ch/martin.jaggi">Martin Jaggi</a> and
      <a href="https://people.csail.mit.edu/alistarh/">Dan Alistarh</a> on low-precision training of neural networks.
   I also spent two summers (2016, 2017) at Google as a Software Engineering intern.</p> -->

    <p> <strong> I am on job market in 2023-2024 and looking for Research Scientist and postdoc positions!
 </strong></p>

</section>

<section>
  <h2>
    Publications
</h2>
<ul id="publications" >

    <li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Understanding the Detrimental Class-level Effects of Data Augmentation</strong>
        </span>
        <br />
        <span class='authors'>
          <strong>Polina Kirichenko</strong>, Mark Ibrahim, Randall Balestriero, Diane Bouchacourt, Rama&nbsp;Vedantam, Hamed Firooz, Andrew&nbsp;Gordon&nbsp;Wilson
        </span>
        <br />
        <span class='conference'>
            <i>ICML workshop on Spurious Correlations, Invariance, and Stability,&nbsp;2023; </i><!--
     --></span>
        <br />
        <span class='conference'>
            <i><strong><i>Neural Information Processing Systems (NeurIPS),&nbsp;2023</i></strong></i><!--
     --></span>
        <br />
        [<a href="https://openreview.net/pdf?id=yageaKlk7S">pdf</a>]
    </li>


    <li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations</strong>
        </span>
        <br />
        <span class='authors'>
          <strong>Polina Kirichenko*</strong>, Pavel Izmailov*, Andrew&nbsp;Gordon&nbsp;Wilson
        </span>
        <br />
        <span class='conference'>
            <i>ICML workshop on Spurious Correlations, Invariance, and Stability,&nbsp;2022; <i><strong><i>oral presentation</i></strong></i></i><!--
     --></span>
        <br />
        <span class='conference'>
            <i><strong><i>International Conference on Learning Representations (ICLR),&nbsp;2023; spotlight (notable-top-25%)</i></strong></i><!--
     --></span>
        <br />
        [<a href="https://arxiv.org/abs/2204.02937">arXiv</a>, <a href="https://github.com/PolinaKirichenko/deep_feature_reweighting">code</a>]
    </li>


    <li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Does Progress On Object Recognition Benchmarks Improve Real-World Generalization?</strong>
        </span>
        <br />
        <span class='authors'>
          Megan Richards, <strong>Polina Kirichenko</strong>, Diane Bouchacourt, Mark Ibrahim
        </span>
        <br />
        <span class='conference'>
            <i>ICML Data-centric Machine Learning Research Workshop,&nbsp;2023; </i><!--
     --></span>
        <br />
        <span class='conference'>
            <i>Under review</i><!--
     --></span>
        <br />
        [<a href="https://arxiv.org/abs/2307.13136">arXiv</a>]
    </li>


	<li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>On Feature Learning in the Presence of Spurious Correlations</strong>
        </span>
        <br />
        <span class='authors'>
          Pavel Izmailov*, <strong>Polina Kirichenko*</strong>, Nate, Gruver*, Andrew&nbsp;Gordon&nbsp;Wilson
        </span>
        <br />
        <span class='conference'>
            <strong><i>Neural Information Processing Systems (NeurIPS),&nbsp;2022</i></strong><!--
     --></span>
     <br />
        [<a href="https://arxiv.org/abs/2210.11369">arXiv</a>, <a href="https://github.com/izmailovpavel/spurious_feature_learning">code</a>]
    </li>

    <li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Chroma-VAE: Mitigating Shortcut Learning with Generative Classifiers</strong>
        </span>
        <br />
        <span class='authors'>
          Wanqian Yang, <strong>Polina Kirichenko</strong>, Micah Goldblum, Andrew&nbsp;Gordon&nbsp;Wilson
        </span>
        <br />
        <span class='conference'>
            <strong><i>Neural Information Processing Systems (NeurIPS),&nbsp;2022</i></strong><!--
     --></span>
     <br />
     [<a href="https://arxiv.org/abs/2211.15231">arXiv</a>]
    </li>

	<li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Does Knowledge Distillation Really Work?</strong>
        </span>
        <br />
        <span class='authors'>
          Samuel Stanton, Pavel Izmailov, <strong>Polina Kirichenko</strong>, Alexander&nbsp;A.&nbsp;Alemi, Andrew&nbsp;Gordon&nbsp;Wilson
        </span>
        <br />
        <span class='conference'>
            <strong><i>Neural Information Processing Systems (NeurIPS),&nbsp;2021</i></strong><!--
     --></span>
        <br />
        [<a href="https://arxiv.org/abs/2106.05945">arXiv</a>]
    </li>
    

	<li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Task-agnostic Continual Learning with Hybrid Probabilistic Models</strong>
        </span>
        <br />
        <span class='authors'>
          <strong>Polina Kirichenko</strong>, Mehrdad Farajtabar, Dushyant Rao, Balaji Lakshminarayanan, Nir&nbsp;Levine, Ang&nbsp;Li, Huiyi&nbsp;Hu, Andrew&nbsp;Gordon&nbsp;Wilson, Razvan Pascanu
        </span>
        <br />
        <span class='conference'>
            <i>ICML Workshop on Invertible Neural Networks, Normalizing Flows, and Explicit Likelihood Models (spotlight talk),&nbsp;2021</i><!--
     --></span>
        <br />
        [<a href="https://arxiv.org/abs/2106.12772">arXiv</a>,
         <a href="hcl-poster-icml.pdf">poster</a>]
    </li>


    <li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Why Normalizing Flows Fail to Detect Out-of-Distribution Data</strong>
        </span>
        <br />
        <span class='authors'>
          <strong>Polina Kirichenko*</strong>, Pavel Izmailov*, Andrew Gordon Wilson
        </span>
        <br />
        <span class='conference'>
            <i>ICML workshop on Invertible Neural Networks and Normalizing Flows,&nbsp;2020</i><!--
     --></span>
        <br />
        <span class='conference'>
            <strong><i>Neural Information Processing Systems (NeurIPS),&nbsp;2020</i></strong><!--
     --></span>
        <br />
        [<a href="https://arxiv.org/abs/2006.08545">arXiv</a>,
         <a href="nf_neurips_poster.pdf">poster</a>]
    </li>
    <li>
        <span class='title'>
            <strong>Semi-Supervised Learning with Normalizing Flows</strong>
        </span>
        <br />
        <span class='authors'>
          Pavel Izmailov*, <strong>Polina Kirichenko*</strong>, Marc Finzi*, Andrew Gordon Wilson
        </span>
        <br />
        <span class='conference'>
            <i>ICML workshop on Invertible Neural Nets and Normalizing Flows,&nbsp;2019</i><!--
     --></span>
        <br />
        <span class='conference'>
            <i>14th Women in Machine Learning workshop (co-located with NeurIPS),&nbsp;2019</i><!--
     --></span>
        <br />
        <span class='conference'>
            <strong><i>International Conference on Machine Learning (ICML),&nbsp;2020</i></strong><!--
     --></span>
        <br />
        [<a href="https://arxiv.org/abs/1912.13025">arXiv</a>,
         <a href="http://proceedings.mlr.press/v119/izmailov20a.html">PMLR</a>,
         <a href="https://github.com/izmailovpavel/flowgmm">code</a>,
         <a href="sslnf_poster.pdf">poster</a>]
    </li>
    <li>
        <span class='title'>
            <strong>Subspace Inference for Bayesian Deep Learning</strong>
        </span>
        <br />
        <span class='authors'>
			Pavel Izmailov*, Wesley Maddox*, <strong> Polina Kirichenko*</strong>, Timur Garipov*, Dmitry Vetrov, Andrew&nbsp;Gordon&nbsp;Wilson
        </span>
        <br />
         <span class='conference'>
            <i>ICML workshop on Uncertainty & Robustness in Deep Learning (contributed talk),&nbsp;2019</i><!--
     --></span>
        <br />
        <span class='conference'>
            <strong><i>Uncertainty in Artificial Intelligence (UAI),&nbsp;2019</i></strong><!--
     --></span>
        <br />
        [<a href="https://arxiv.org/abs/1907.07504">arXiv</a>,
         <a href="https://github.com/wjmaddox/drbayes">code</a>,
         <a href="udl-poster.pdf">UDL poster</a>,
         <a href="uai-poster.pdf">UAI poster</a>]
    </li>
    <li>
        <span class='title'>
            <strong>SWALP: Stochastic Weight Averaging in Low-Precision Training</strong>
        </span>
        <br />
        <span class='authors'>
			Guandao Yang, Tianyi Zhang, <strong>Polina Kirichenko</strong>, Junwen Bai, Andrew Gordon Wilson, Christopher&nbsp;De&nbsp;Sa
        </span>
        <br />
        <span class='conference'>
             <strong><i>International Conference on Machine Learning (ICML),&nbsp;2019</i></strong><!--
     --></span>
        <br />
        [<a href="https://arxiv.org/abs/1904.11943">arXiv</a>,
         <a href="http://proceedings.mlr.press/v97/yang19d.html">PMLR</a>,
         <a href="https://github.com/stevenygd/SWALP">code</a>]
    </li>


  </section>



  <section>
  <h2>
    Workshop Papers
</h2>
<ul id="workshops" >

	      <li>
        <span class='title'>
            <strong>Effective Surrogate Models for Protein Design with Bayesian Optimization</strong>
        </span>
        <br />
        <span class='authors'>
            Nate Gruver, Samuel Stanton, <strong>Polina Kirichenko</strong>, Marc Finzi, Phillip Maffettone, Vivek Myers, Emily Delaney, Peyton Greenside, Andrew Gordon Wilson
        </span>
        <br />
        <span class='conference'>
            <i>ICML Workshop on Computational Biology,&nbsp;2021</i><!--
     --></span>
        <br />
        [<a href="https://icml-compbio.github.io/2021/papers/WCBICML2021_paper_61.pdf">workshop PDF</a>]
    </li>

      <li>
        <span class='title'>
            <strong>Invertible Convolutional Networks</strong>
        </span>
        <br />
        <span class='authors'>
            Marc Finzi, Pavel Izmailov, <strong>Polina Kirichenko</strong>, Andrew Gordon Wilson
        </span>
        <br />
        <span class='conference'>
            <i>ICML workshop on Invertible Neural Nets and Normalizing Flows (splotlight talk),&nbsp;2019</i><!--
     --></span>
        <br />
        [<a href="https://invertibleworkshop.github.io/accepted_papers/pdfs/INNF_2019_paper_26.pdf">workshop PDF</a>,
         <a href="iconv_poster.pdf">poster</a>,
         <a href="iconv_slides.pdf">slides</a>]
    </li>

</section>



<section>
  <h2>
    Awards
</h2>
<ul id="workshops" >

	<li>
        <span class='title'>
            <strong>DeepMind Fellowship 2019-2020</strong>
        </span>
    </li>

      <li>
        <span class='title'>
            <strong>Google Anita Borg Memorial Scholarship 2015 (Women Techmakers Scholarship)</strong>
        </span>
    </li>

    <li>
        <span class='title'>
            <strong>Golden HSE Award (Alumni Success: Best Academic Achievement) 2019</strong>
        </span>
    </li>


    <li>
        <span class='title'>
            <strong>Ilya Segalovich Scholarship (Yandex) 2016, 2017</strong>
        </span>
    </li>

</section>



<section>
  <h2>
    Talks
</h2>
<ul id="talks" >

	<li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations</strong>
        </span>
        <br />
        <span class='place'>
        Oral presentation at ICML 2022 Workshop on Spurious Correlations, Invariance, and Stability
        </span>
        <br />
        [<a href="https://icml.cc/virtual/2022/workshop/13461">video</a>]
    </li>

	<li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Applications of normalizing flows: semi-supervised learning, anomaly detection, and continual learning</strong>
        </span>
        <br />
        <span class='place'>
        <strong>Keynote talk</strong> at ICML 2021 Workshop on Representation Learning for Finance and E-Commerce Applications
        </span>
        <br />
        [<a href="https://icml.cc/Conferences/2021/ScheduleMultitrack?event=8361">video</a>]
    </li>

    <li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Task-agnostic Continual Learning with Hybrid Probabilistic Models</strong>
        </span>
        <br />
        <span class='place'>
        Spotlight talk at INNF+ workshop at ICML 2021
        </span>
        <br />
        [<a href="https://icml.cc/virtual/2021/workshop/8360">video</a>]
    </li>

	<li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Continual Learning in Neural Networks: on Catastrophic Forgetting and Beyond</strong>
        </span>
        <br />
        <span class='place'>
        Bayesian Methods Research Group seminar (in Russian)
        </span>
        <br />
        [<a href="https://www.youtube.com/watch?v=qhLuj2km5gE">video</a>,
        <a href="https://bayesgroup.github.io/bmml_sem/2021/Kirichenko_Continual-learning.pdf">slides</a>]
    </li>

	<li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Understanding Semantic Anomaly Detection with Generative Networks</strong>
        </span>
        <br />
        <span class='place'>
        ML Collective 2021, Deep Learning: Classics and Trends
        </span>
        <br />
        [<a href="https://rosanneliu.com/dlctfs/dlct_210226.pdf">slides</a>]
    </li>

	<li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Normalizing flows for anomaly detection</strong>
        </span>
        <br />
        <span class='place'>
      CogSys Talks, Technical University of Denmark
        </span>
        <br />
        [<a href="https://youtu.be/Bts0jLU41a8?t=1486">video</a>]
    </li>

	<li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Anomaly detection via Generative Models</strong>
        </span>
        <br />
        <span class='place'>
      Open Data Science DafaFest 2020, Uncertainty in ML Workshop
        </span>
        <br />
        [<a href="https://ods.ai/tracks/uncertainty-estimation-in-ml-df2020/4b59299d-0f36-4cfb-b72d-c3a2c9140f48">video</a>]
    </li>

	<li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Why Normalizing Flows Fail to Detect Out-of-Distribution Data</strong>
        </span>
        <br />
        <span class='place'>
      INNF+ workshop at ICML 2020; NeurIPS 2020
        </span>
        <br />
        [<a href="https://slideslive.com/38931453/why-normalizing-flows-fail-to-detect-outofdistribution-data">ICML video</a>,
         <a href="https://nips.cc/virtual/2020/protected/poster_ecb9fe2fbb99c31f567e9823e884dbec.html">NeurIPS video</a>]
    </li>

	<li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Scalable Bayesian Inference in Low-Dimensional Subspaces</strong>
        </span>
        <br />
        <span class='place'>
      Higher School of Economics
        </span>
        <br />
        [<a href="https://youtu.be/2ViJ9ncnl7U">video</a>]
    </li>
  
    <li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>How do we build neural networks we can trust?</strong>
        </span>
        <br />
        <span class='place'>
      Broad Institute of MIT and Harvard 
        </span>
        <br />
        [<a href="https://www.youtube.com/watch?v=GXs9Pmp6IKQ&feature=youtu.be&list=PLlMMtlgw6qNjROoMNTBQjAcdx53kV50cS">video</a>,
        <a href="MIA_talk.pdf">slides</a>]
    </li>

    <li style="margin-bottom: 10px;">
        <span class='title'>
            <strong>Subspace Inference for Bayesian Deep Learning</strong>
        </span>
        <br />
        <span class='place'>
        ICML workshop on Uncertainty & Robustness in Deep Learning
        </span>
        <br />
        [<a href="https://www.facebook.com/icml.imls/videos/320132412242165/?__xts__[0]=68.ARAVE0qFWSNt-GsHzKLAlU1lZSCw4FENJXcyjPNmenkT3SSPm4B2Ib1MPabxMBWmdBT2zgCjJHensO1ZQdKuezoWD7ycEdtgPu0YwfjA3d0F6tqqeJL2-xzR-VWLWMxu97LclHmIA9pSCOG_43utM8o-_q8Tc6LYrnm57RHX3uBGezj53Ee8Qbgne6kBiDJxuQIPpKEuszxmkvgSr3qN1QvIcm9QpIU7jiNbwat2Se6rIm7aj0dV2RxtrgrahnyDDHcUqq0HRfHlkLGfX8jsO_IeKoEqDFelMVJrQLNg0196rM8xJTbB1jrMPV2GlZJr-ebE4h_SPuUa62LVfoxJFBszgk-RUvmvDgI&__tn__=-R">video</a>,
        <a href="subspaces_slides.pdf">slides</a>]
    </li>



  </section>



    </div>
    <script src="/assets/js/scale.fix.js"></script>
  </body>
</html>

